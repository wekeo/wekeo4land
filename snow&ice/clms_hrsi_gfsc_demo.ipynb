{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0c4b33d-de6f-4dc7-ac5f-34f4e5b6f531",
   "metadata": {},
   "source": [
    "<img src='img/LogoWekeo_Copernicus_RGB_0.png' alt='' align='centre' width='10%'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e0862-f17c-4f2b-8336-3d52bdbc01aa",
   "metadata": {},
   "source": [
    "### <a id='wekeo_hda_install'></a>Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5291b0-e7c6-487b-9e9b-b5e2c7c8777b",
   "metadata": {},
   "source": [
    "<h4>This Jupyter notebook includes examples on:</h4>\n",
    "<li>How to access GFSC products through HDA API</li>\n",
    "<li>Read and visualize GFSC Products</li>\n",
    "<li>Manipulate QCFLAGS layer to filter data according to sensor type</li>\n",
    "<li>Manipulate AT layer to filter data according to data age</li>\n",
    "\n",
    "<h4>CLMS HRSI GFSC Product:</h4>\n",
    "The daily cumulative Gap-filled Fractional Snow Cover (GFSC) product is generated in NRT for\n",
    "the entire EEA38+UK domain based on SAR data from the S1 constellation and optical data\n",
    "from the S2 constellation. The product merges the latest observations available to form a\n",
    "spatially complete overview of snow conditions. The product provides the extent of the snow\n",
    "cover per pixel as a percentage (0% – 100%) with a spatial resolution of 60 m x 60 m. The\n",
    "product uses Fractional Snow Cover (FSC), Wet/Dry Snow (WDS) and SAR Wet Snow (SWS) products as input to form a spatially complete composite of\n",
    "snow conditions, to reduce observational gaps due to clouds and lack of sensor coverage on a\n",
    "daily basis. The product applies the on-ground FSC, and SWS and\n",
    "presents the combined information as FSC.\n",
    "<br><br>\n",
    "Additional information about GFSC product can be found in the <a href=\"https://land.copernicus.eu/user-corner/technical-library/hrsi-snow-pum\">Product User Manual (PUM).</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970329d9-e9f6-49cb-b646-e2a5cddec6b7",
   "metadata": {},
   "source": [
    "<h4>Importing  the required libraries</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136b4bc0-1ab5-4722-a54f-b3fb039617ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and definitions\n",
    "import os, sys, json, datetime, dateutil, shutil, tempfile, zipfile\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from copy import deepcopy\n",
    "prod_dir = os.path.realpath(\"products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc74179-5524-464d-abfc-f19d24480a80",
   "metadata": {},
   "source": [
    "HDA API Python library is available by default with \"miniwekeolab\" kernel, but not with other kernels. We can make an exception to install it, if it does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388775d-0d8a-423c-ac41-a51198dc3745",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # hda library is not in Python 3 kernel (if selected)\n",
    "    import hda\n",
    "except:\n",
    "    print(\"Cannot import hda, installing.\")\n",
    "    os.system(\"pip install hda\")\n",
    "    try:\n",
    "        import hda\n",
    "        print(\"Successful\")\n",
    "    except:\n",
    "        print(\"Cannot import\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f165a6f0-524b-4c11-9cc8-4fa3f243a9f1",
   "metadata": {},
   "source": [
    "\"xmltodict\" Python library is not available by default with \"miniwekeolab\" kernel. We can make an exception to install it, if it does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f474b9-3d88-4568-9060-b44854d45ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # xmltodict library is not in miniwekeolab kernel (if selected)\n",
    "    import xmltodict\n",
    "except:\n",
    "    print(\"Cannot import xmltodict, installing.\")\n",
    "    os.system(\"pip install xmltodict\")\n",
    "    try:\n",
    "        import xmltodict\n",
    "        print(\"Successful\")\n",
    "    except:\n",
    "        print(\"Cannot import\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6500ff5-9849-476c-8e86-de9fe6f899e6",
   "metadata": {},
   "source": [
    "<h4>Accessing GFSC Products using HDA Library</h4>\n",
    "Harmonized data access (HDA) client can be used to access and download CLMS HRSI products. How to use the client is described in <a href=\"https://www.wekeo.eu/docs/how-to-use-hda\">Wekeo documentation.</a> How to use HDA Python library is also documented </a href=\"https://hda.readthedocs.io/en/latest/\">in a separate documentation</a> and a smaller tutorial can be found <a href=\"https://www.wekeo.eu/docs/hda-python-lib\">here.</a> Wekeo also maintains a larger tutorial using Jupyter notebook <a href=\"https://github.com/wekeo/wekeo4data\">in Github</a>. This notebook is also provided in the public folder of Wekeo Github at \"public/wekeo4data/wekeo-hda/wekeo_harmonised_data_access_api.ipynb\".\n",
    "<br><br>\n",
    "In this notebook, we will use HDA Python library with the default credentials file (~/.hdarc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f9f992-bed2-4477-b77b-eeacdbcb6068",
   "metadata": {},
   "source": [
    "Create ~/.hdarc file and enter credentials if it doesnt exist: (replace \"username\" and \"password\" with correct ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c2bcf4-48c5-4090-8399-8eb13b489cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(os.path.expanduser('~'),'.hdarc')):\n",
    "    with open(os.path.join(os.path.expanduser('~'),'.hdarc'),\"w\") as f:\n",
    "        f.write(\"url: https://wekeo-broker.prod.wekeo2.eu/databroker\\n\")\n",
    "        f.write(\"user: username\\n\")\n",
    "        f.write(\"password: password\\n\")\n",
    "    print(\"Credentials file created\")\n",
    "else:\n",
    "    print(\"Credentials file already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc67f9-3883-4dd2-8b12-9a08f764d5b4",
   "metadata": {},
   "source": [
    "Initialize an HDA Client. Here, the user credentials are read from \"~/.hdarc\" file and default configuration is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f4005a-4a66-446a-b62c-ebdd92cf1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hda_client = hda.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2687abac-cda8-4fbd-9dc8-b6b3ac1c5691",
   "metadata": {},
   "source": [
    "An example query JSON (will not be used in the examples) to search products:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfa087c-95db-4243-8bbf-4bd3b2a123cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "  \"datasetId\": \"EO:CRYO:DAT:HRSI:GFSC\",\n",
    "  \"boundingBoxValues\": [\n",
    "    {\n",
    "      \"name\": \"bbox\",\n",
    "      \"bbox\": [\n",
    "        4.0488399662761605,\n",
    "        60.64709920038568,\n",
    "        9.213189474039462,\n",
    "        61.81526952644772\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"dateRangeSelectValues\": [\n",
    "    {\n",
    "      \"name\": \"Observed\",\n",
    "      \"start\": \"2022-03-13T00:00:00.000Z\",\n",
    "      \"end\": \"2022-03-13T00:00:00.000Z\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f9abf7-1bcf-41a8-a8e2-1146d27d3955",
   "metadata": {},
   "source": [
    "Query JSON can be copy pasted from a manual search in Wekeo Data Explorer:\n",
    "<div style='text-align:center;'>\n",
    "<figure><img src='./img/apicall.png' width='50%' />\n",
    "    <figcaption><i>S2 Tile T32VMN</i></figcaption>\n",
    "</figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7da694b-ac40-48ff-b977-4ed7e1baebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "  \"datasetId\": \"EO:CRYO:DAT:HRSI:GFSC\",\n",
    "  \"boundingBoxValues\": [\n",
    "    {\n",
    "      \"name\": \"bbox\",\n",
    "      \"bbox\": [\n",
    "        34.871454195608834,\n",
    "        38.98657296199103,\n",
    "        36.45614160450388,\n",
    "        39.91031559266836\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"dateRangeSelectValues\": [\n",
    "    {\n",
    "      \"name\": \"Observed\",\n",
    "      \"start\": \"2022-02-11T00:00:00.000Z\",\n",
    "      \"end\": \"2022-02-15T00:00:00.000Z\"\n",
    "    }\n",
    "  ],\n",
    "  \"stringInputValues\": [\n",
    "    {\n",
    "      \"name\": \"cloudCover\",\n",
    "      \"value\": \"30\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf8a3e8-d68a-42fb-8ff4-a78c59e03c25",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr><td>\n",
    "    We can create a query for a single day and tile, using \"dateRangeSelectValues\" and \"stringInputValues\" options.\n",
    "        <br><br>\n",
    "    For example, T32TVM in Scandinavian mountains, on 13.03.2022:\n",
    "    </td><td>\n",
    "<div style='text-align:center;'>\n",
    "<figure><img src='./img/T32VMN.png' width='50%' />\n",
    "    <figcaption><i>S2 Tile T32VMN</i></figcaption>\n",
    "</figure>\n",
    "</div>\n",
    "        </td></tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd71676-e173-44d5-8fdf-e22afa5ca0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query by tile and date\n",
    "tile = 'T32VMN'\n",
    "day = '14.03.2022'\n",
    "\n",
    "query = {\n",
    "  \"datasetId\": \"EO:CRYO:DAT:HRSI:GFSC\",\n",
    "  \"dateRangeSelectValues\": [\n",
    "    {\n",
    "      \"name\": \"Observed\",\n",
    "      \"start\": datetime.datetime.strptime(day,\"%d.%m.%Y\").strftime(\"%Y-%m-%dT00:00:00.000Z\"),\n",
    "      \"end\": datetime.datetime.strptime(day,\"%d.%m.%Y\").strftime(\"%Y-%m-%dT00:00:00.000Z\"),\n",
    "    }\n",
    "  ],\n",
    "  \"stringInputValues\": [\n",
    "    {\n",
    "      \"name\": \"productIdentifier\",\n",
    "      \"value\": tile\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9ca41b-d9eb-47f5-a3ec-fc1851b68390",
   "metadata": {},
   "source": [
    "Search the database with HDA Client and the query. Use a shorter timeout configuration, in case there is a problem in the connection or account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31605175-b5de-4c8b-879e-20cbf59a9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "hda_client.time_sleep = 10\n",
    "hda_client.timeout = 10\n",
    "\n",
    "try:\n",
    "    matches = hda_client.search(query)\n",
    "    hda_success = True\n",
    "except Exception as e:\n",
    "    hda_success = False\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4abc5b1-3c9e-4950-9faa-6673e27991f2",
   "metadata": {},
   "source": [
    "If a problem occured, e.g. the user is not registered, create an object to use if there is any products downloaded before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cd6c49-2ac9-4247-8360-2e5496316d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hda_success:\n",
    "    matches = []\n",
    "    for product in os.listdir(prod_dir):\n",
    "        try:\n",
    "            # test if folder name fits the product filename format\n",
    "            day = datetime.datetime.strptime(product.split('_')[1].split('-')[0],\"%Y%m%d\")\n",
    "            curation_time = datetime.datetime.utcfromtimestamp(int(product.split('_')[5]))\n",
    "            # add product name to the object in the form that it can be used in the line later\n",
    "            # matches[0].results[0]['productInfo']['product']\n",
    "            match = lambda: None\n",
    "            match.results = [{'productInfo':{'product':product}}]\n",
    "            matches.append(match)\n",
    "        except:\n",
    "            print(\"A folder/file in products folder is not a valid product. Skipped.\")\n",
    "    print(len(matches), \"products found in products folder.\")\n",
    "else:\n",
    "    print(\"HDA Client response successful. HDA Client will be used.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501267ab-da1a-4484-83af-8ee78fef51ff",
   "metadata": {},
   "source": [
    "Parse the response from HDA client and create a list of dictionaries with additional metadata to handle the data more compactly.\n",
    "<br>\n",
    "List structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e77aa-ccf4-471e-86f7-a1c6ebe09544",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    {\n",
    "        'title': str, \n",
    "        'tile': str, \n",
    "        'day': datetime.datetime, \n",
    "        'curation_time': datetime.datetime, \n",
    "        'dir': str\n",
    "    },\n",
    "    {\n",
    "        'title': str, \n",
    "        'tile': str, \n",
    "        'day': datetime.datetime, \n",
    "        'curation_time': datetime.datetime, \n",
    "        'dir': str\n",
    "    }\n",
    "];\n",
    "\n",
    "# only for descriptive usage. this cell does not do anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759af917-7109-47b9-a875-49ce27bef28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(matches), \"products found\")\n",
    "# reparse response for a custom list\n",
    "products = []\n",
    "for match in matches:        \n",
    "    product = match.results[0]['productInfo']['product']\n",
    "    tile = product.split('_')[3]\n",
    "    day = datetime.datetime.strptime(product.split('_')[1].split('-')[0],\"%Y%m%d\")\n",
    "    curation_time = datetime.datetime.utcfromtimestamp(int(product.split('_')[5]))\n",
    "    products.append({\n",
    "        'title':product,\n",
    "        'tile':tile,\n",
    "        'day':day,\n",
    "        'curation_time':curation_time\n",
    "    })\n",
    "    \n",
    "# summarize products \n",
    "print(\"Day\\t\\tTile\\tCuration time\")\n",
    "for product in products:\n",
    "    print(\n",
    "        '\\t'.join([\n",
    "            str(product['day']).split()[0],product['tile'],str(product['curation_time'])\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "if products == []:\n",
    "    print(\"No products are available in the disk. Rest of the notebook will not work.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a249f9-1ae1-48c6-85e5-fc6754911e95",
   "metadata": {},
   "source": [
    "Download the products to temporary folders and move them to the \"products directory\" which was defined in the beginning.\n",
    "<li>Products are downloaded as zip files, but without file extensions. Extract the files before moving them to the products directory.</li>\n",
    "<li>Products may be downloaded before, if that is the case (folder exists), skip the download.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186b8de-8633-48d0-b96d-0c641e421d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(prod_dir,exist_ok=True)\n",
    "for product in products:\n",
    "    if product['title'] not in os.listdir(prod_dir):\n",
    "        # use a temporary directory\n",
    "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "            # find the products in the HDA client response and call download method\n",
    "            [match.download(download_dir = tmp_dir) for match in matches if match.results[0]['productInfo']['product'] == product['title'] ]\n",
    "            # rename file to zip to use same dir for product dir, to be safe in real product folder\n",
    "            os.rename(os.path.join(tmp_dir,product['title']), os.path.join(tmp_dir,product['title']) + '.zip')\n",
    "            # unzip\n",
    "            with zipfile.ZipFile(os.path.join(tmp_dir,product['title']) + '.zip') as zf:\n",
    "                zf.extractall(os.path.join(tmp_dir))\n",
    "            # copy to the \"real\" product dir\n",
    "            shutil.copytree(os.path.join(tmp_dir,product['title']),os.path.join(prod_dir,product['title']))\n",
    "            print(product['title'],\"was downloaded to\",prod_dir)\n",
    "    else:\n",
    "        print(product['title'],\"is already in product directory\")\n",
    "    # add directory information to be used later\n",
    "    product['dir'] = os.path.join(prod_dir,product['title'])\n",
    "\n",
    "# Note: HDA Client can download all results at once:\n",
    "# matches.download(download_dir = path_to_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26f7a3a-b127-4e80-b557-db56e50f00da",
   "metadata": {},
   "source": [
    "<h4>Read and visualize products</h4>\n",
    "Create functions to read products rasters and metadata and keep them compactly in dictionaries:\n",
    "<br><br>\n",
    "Main function will get the directory and the title of the product as arguments and return a single dictionary with all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f70b9-1971-4650-a0ab-a694bce23111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read tif image\n",
    "def readTif(file_tif):\n",
    "\n",
    "    ds = gdal.Open(file_tif)\n",
    "    # Projection\n",
    "    proj = ds.GetProjection()\n",
    "    # Raster data\n",
    "    data = ds.GetRasterBand(1).ReadAsArray()\n",
    "    # colormap\n",
    "    color_table = ds.GetRasterBand(1).GetRasterColorTable()\n",
    "    cmp = None\n",
    "    if color_table is not None:\n",
    "        cmp = []\n",
    "        for i in range(color_table.GetCount()):\n",
    "            color = color_table.GetColorEntry(i)\n",
    "            cmp.append((color[0]/255, color[1]/255, color[2]/255))\n",
    "    ds = None\n",
    "    return data, proj, cmp\n",
    "\n",
    "# function to read all rasters and xml metadata of gfsc\n",
    "def readProductFiles(directory,title):   \n",
    "    # read tif rasters\n",
    "    gf, proj_gf, cmp_gf = readTif(os.path.join(directory,title) + '_GF.tif')\n",
    "    qc, proj_qc, cmp_qc = readTif(os.path.join(directory,title) + '_QC.tif')\n",
    "    qcflags = readTif(os.path.join(directory,title) + '_QCFLAGS.tif')[0]\n",
    "    at = readTif(os.path.join(directory,title) + '_AT.tif')[0]\n",
    "    \n",
    "    # read xml metadata\n",
    "    meta = xmltodict.parse(open(os.path.join(directory,title) + '_MTD.xml','r').read())\n",
    "    \n",
    "    return gf, cmp_gf, qc, cmp_qc, qcflags, at, meta, proj_gf\n",
    "\n",
    "# function to organize data into single dictonary\n",
    "def readProductData(directory,title):\n",
    "    gf, cmp_gf, qc, cmp_qc, qcflags, at, meta, proj = readProductFiles(directory,title)\n",
    "    \n",
    "    # make a dict for convenient reading\n",
    "    productData = {\n",
    "        'GF':gf, \n",
    "        'GF_cmp':cmp_gf, \n",
    "        'QC':qc, \n",
    "        'QC_cmp':cmp_qc, \n",
    "        'QCFLAGS':qcflags, \n",
    "        'AT':at, \n",
    "        'meta':meta, \n",
    "        'proj':proj\n",
    "    }\n",
    "    \n",
    "    return productData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68211610-945f-4e21-9018-559ef00ebd12",
   "metadata": {},
   "source": [
    "Read data and metadata of the first product in the list using the function and directories defined previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1176208a-18c3-448b-995a-6f46ce25b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = products[0]\n",
    "productData = readProductData(product['dir'],product['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92ceba-f583-467a-89d8-15ddd9cc1e73",
   "metadata": {},
   "source": [
    "The color table in the product includes No data label (255) as transparent. Since the notebook color is white, no data pixels will be shown as white, which will not be distinguisable from snow pixels. Thus, we should use a different color for no data pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cdd8b4-a8ab-4719-9913-3da225d8cffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "productData['GF_cmp'][-1] = (255/255.,192/255.,203/255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45265d8-7339-4e3c-b23c-6793fe8840e9",
   "metadata": {},
   "source": [
    "Default figure size of \"matplotlib\" is too small for the screen, modify it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429f6b9-8f08-4613-abf3-2c3dfacbb906",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde397be-113b-4f52-94e9-7bc323ceea1b",
   "metadata": {},
   "source": [
    "Draw GF layer using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c946f0f-3126-4efa-93e0-ba950fccb5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(productData['GF'], cmap = ListedColormap(productData['GF_cmp']), interpolation = 'nearest');\n",
    "plt.clim(0, 255)\n",
    "plt.colorbar();\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902abe0-1b8f-41ab-8cd9-702f340e7e04",
   "metadata": {},
   "source": [
    "GF layer shows gap-filled FSC. It contains data from up to 7 days before. XML metadata in the product includes the metadata information from all the input products. We can use that information to list the input products and their sensing times and calculate the age of data for each product, relatively to the GFSC product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d5ec5f-5851-4442-a580-f42839e96fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TYPE\\tSENSING TIME\\t\\tAGE')\n",
    "for input_meta in productData['meta']['gmd:MD_Metadata']['gmd:series']['gmd:DS_OtherAggregate']['gmd:seriesMetadata']:\n",
    "    input_title = input_meta['gmd:MD_Metadata']['gmd:fileIdentifier']['gco:CharacterString']\n",
    "    input_type = input_title.split('_')[0]\n",
    "    input_startDate = dateutil.parser.isoparse(input_meta['gmd:MD_Metadata']['gmd:identificationInfo']['gmd:MD_DataIdentification']['gmd:extent']['gmd:EX_Extent']['gmd:temporalElement']['gmd:EX_TemporalExtent']['gmd:extent']['gml:TimePeriod']['gml:beginPosition'])\n",
    "    input_startDate = input_startDate.replace(microsecond=0)\n",
    "    input_age = product['day'] + datetime.timedelta(days=1) - input_startDate\n",
    "    print(input_type + '\\t' + input_startDate.strftime('%Y-%m-%d %H:%M:%S') + '\\t' + str(input_age))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f181316-06f5-4818-8f80-68968c719caa",
   "metadata": {},
   "source": [
    "XML metadata has the temporal information as a list, but AT layer has the temporal information for each pixel. Sensing time of each pixel is encoded as \"Unix time\" (seconds from 1.1.1970) in AT layer. We can create a raster of \"age\" which shows how old is the data in days (decimal), from the end of the product day (e.g. the age for a sensing at noon in the same day will be 12 hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a5016-d275-4c00-a0d0-3e7c8c7c35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_midnight_timestamp = datetime.datetime.timestamp(product['day'] + datetime.timedelta(days=1))\n",
    "productData['age'] = (product_midnight_timestamp - productData['AT'])/(60*60*24.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1c6627-c0fa-4ea5-9566-a42f78bcb488",
   "metadata": {},
   "source": [
    "When no-data is present, AT layer has the value \"0\". To handle that, we can use \"NaN\" in the new age raster instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76048931-3397-482a-964a-5c7ebf4f41cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.place(productData['age'],productData['AT'] == 0,np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22504de-6f02-4649-8835-c00af2d025e6",
   "metadata": {},
   "source": [
    "Draw the new \"age\" raster using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d375d4-9e18-4ee0-b889-1ba79b95758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(productData['age'],  cmap = 'tab20b', interpolation = 'nearest');\n",
    "plt.colorbar();\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d37fe4-dc13-4046-b8d3-b51c9b1380bc",
   "metadata": {},
   "source": [
    "<h4>Manipulating AT layer to filter out data according to age of the pixels</h4>\n",
    "Using the age raster, we can filter out pixels which are \"too old\" for us. Create a new GF raster with only the pixels with \"age\" not more than 4 days (Max 3 days old data). \n",
    "<li>\"invalid value encountered\" warning will appear due to np.nan in age, but result is false for those pixels. Thus, they won't disturb the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0b3219-4d1a-4f32-a50a-282398fa0d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_4days = deepcopy(productData['GF'])\n",
    "np.place(gf_4days, productData['age'] > 4, 255)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"GF\")\n",
    "plt.imshow(\n",
    "    productData['GF'], cmap = ListedColormap(productData['GF_cmp']), interpolation = 'nearest'\n",
    ");\n",
    "plt.clim(0, 255)\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);\n",
    "# change the color to a different one\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"4 Days Mask\")\n",
    "plt.imshow(\n",
    "    productData['age'] <= 4, cmap = 'PiYG', interpolation = 'nearest'\n",
    ");\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"GF 4 Days\")\n",
    "plt.imshow(\n",
    "    gf_4days, cmap = ListedColormap(productData['GF_cmp']), interpolation = 'nearest'\n",
    ");\n",
    "plt.clim(0, 255)\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5610a-a9b2-427f-87ff-9cb3d064b209",
   "metadata": {},
   "source": [
    "<h4>Manipulating QCFLAGS layer to filter out data according to sensor type of the pixels</h4>\n",
    "QCFLAGS layer is encoded bitwise. It has information for 7 different cases as a combination. Thus, only reading integer values directly from the raster will not make sense.\n",
    "Draw QCFLAGS raster using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc318e6-4167-48ae-a504-86f453b21b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"QCFLAGS\")\n",
    "plt.imshow(\n",
    "    productData['QCFLAGS'], cmap = 'Greys', interpolation = 'nearest'\n",
    ");\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aafcb0-6580-4440-8177-8747d41ad232",
   "metadata": {},
   "source": [
    "We should read the raster bit by bit, and use the information according to <a href=\"https://land.copernicus.eu/user-corner/technical-library/hrsi-snow-pum\">the product user manual:</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d469c0c-7342-409b-9972-b22e8965b869",
   "metadata": {},
   "source": [
    "➔ bit 0: sun elevation angle too\n",
    "low for an accurate\n",
    "topographic correction (from\n",
    "MAJA) (active=1) (only valid if\n",
    "bit 6 is 0)\n",
    "\n",
    "➔ bit 1: solar elevation angle\n",
    "tangent to slope (from MAJA)\n",
    "(active=1) (only valid if bit 6\n",
    "is 0)\n",
    "\n",
    "➔ bit 2: water (from EU-Hydro)\n",
    "(active=1)\n",
    "\n",
    "➔ bit 3: TCD too high for\n",
    "accurate forest correction\n",
    "(TCD>90%) (active=1) (only\n",
    "valid if bit 6 is 0)\n",
    "\n",
    "➔ bit 4: snow detected under\n",
    "thin clouds (active=1) (only\n",
    "valid if bit 6 is 0)\n",
    "\n",
    "➔ bit 5: TCD not defined or not\n",
    "available (active=1) (only\n",
    "valid if bit 6 is 0)\n",
    "\n",
    "➔ bit 6: sensor type of the\n",
    "satellite data (optical=0,\n",
    "radar=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f482e-c81a-484b-8f27-4891f65cfc82",
   "metadata": {},
   "source": [
    "Create a function to use bit operations to read a single bit as a boolean raster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe90ac28-25de-4d24-afba-5a26821aac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBit(data,bit):\n",
    "    # shift the bits to the right until the bit in question is in first digit\n",
    "    mask = np.right_shift(data,bit)\n",
    "    # apply \"AND 00000001\" operation to get the value as 0 or 1.\n",
    "    mask = np.bitwise_and(mask,1)\n",
    "    return mask.astype(np.bool)\n",
    "\n",
    "# Google \"nth bit of a number\" for the theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cef9962-b6c7-42e0-ac05-101b988689d5",
   "metadata": {},
   "source": [
    "Read all the bits and visualize them using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfbcb7f-d115-4771-a194-b020d904cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bit in range(1,7):\n",
    "    plt.subplot(2, 3, bit)\n",
    "    plt.title(\"Bit \" + str(bit))\n",
    "    plt.imshow(\n",
    "        getBit(productData['QCFLAGS'],bit), cmap = 'binary', interpolation = 'nearest'\n",
    "    );\n",
    "    plt.xticks([]);\n",
    "    plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6760ee33-ef62-49c0-bf6c-fe88c7564df5",
   "metadata": {},
   "source": [
    "Another example to read QCFLAGS raster can be found in \"Webinar #2 (13 Oct. 2022): High Resolution Snow and Ice Monitoring\" at <a href=\"https://land.copernicus.eu/pan-european/biophysical-parameters/high-resolution-snow-and-ice-monitoring/user-section\">CLMS HRSI User Section website.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6ae688-e879-4e3e-a818-1c0f6770175b",
   "metadata": {},
   "source": [
    "Now, we can use the same function to filter or use the GF layer according to different information from QCFLAGS. First, we can separate the GF raster according to sensor type. If Bit 6 is 1, then the pixel is from radar (S1) and if it is 0, then the sensor is optical (S2). We can create rasters and replace filtered values with no data value (255):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f788ce1d-c62e-4d25-9331-6364c800e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_optical = deepcopy(productData['GF'])\n",
    "gf_radar = deepcopy(productData['GF'])\n",
    "np.place(gf_radar, ~getBit(productData['QCFLAGS'],6), 255)\n",
    "np.place(gf_optical, getBit(productData['QCFLAGS'],6), 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494a6c48-7119-44c9-8551-575e18c346a3",
   "metadata": {},
   "source": [
    "Draw the separated rasters together using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f995ffb-5e6e-43e3-a215-83ec353fc0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"GF\")\n",
    "plt.imshow(\n",
    "    productData['GF'], cmap = ListedColormap(productData['GF_cmp']),interpolation = 'nearest'\n",
    ");\n",
    "plt.clim(0, 255)\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Optical only\")\n",
    "plt.imshow(\n",
    "    gf_optical, cmap = ListedColormap(productData['GF_cmp']),interpolation = 'nearest'\n",
    ");\n",
    "plt.clim(0, 255)\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Radar only\")\n",
    "plt.imshow(\n",
    "    gf_radar, cmap = ListedColormap(productData['GF_cmp']),interpolation = 'nearest'\n",
    ");\n",
    "plt.clim(0, 255)\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab71dc3f-3ce8-424c-9f02-e78c1a84092e",
   "metadata": {},
   "source": [
    "<h4>One last example</h4>\n",
    "We can merge information from AT and QCFLAGS layers to filter pixels from GF layer, for example only from optical sensor and not older than 2 days:\n",
    "<li>\"invalid value encountered\" warning will appear due to np.nan in age, but result is false for those pixels. Thus, they won't disturb the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734b065-50ac-4c76-abc4-6765295dd9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_day_optical = deepcopy(productData['GF'])\n",
    "np.place(gf_day_optical, getBit(productData['QCFLAGS'],6), 255)\n",
    "np.place(gf_day_optical, productData['age'] > 1, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd47156-3abe-4db2-b927-4feffe82f978",
   "metadata": {},
   "source": [
    "Draw the GF and filtered GF using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2209a-0917-4204-8334-f2e334864eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"GF\")\n",
    "plt.imshow(\n",
    "    productData['GF'], cmap = ListedColormap(productData['GF_cmp']), interpolation = 'nearest'\n",
    ");\n",
    "plt.clim(0, 255)\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"1 day  Optical Only\")\n",
    "plt.imshow(\n",
    "    gf_day_optical, cmap = ListedColormap(productData['GF_cmp']), interpolation = 'nearest'\n",
    ");\n",
    "plt.clim(0, 255)\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

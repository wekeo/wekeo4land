{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a74d53",
   "metadata": {},
   "source": [
    "<img src='../../media/common/LogoWekeo_Copernicus_RGB_0.png' align='left' height='96px'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d3089",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e0862-f17c-4f2b-8336-3d52bdbc01aa",
   "metadata": {},
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e17c7",
   "metadata": {},
   "source": [
    "This Jupyter notebook includes examples on:\n",
    "- Access GFSC products through the HDA API\n",
    "- Read and visualize GFSC products\n",
    "- Manipulate the QCFLAGS layer to filter data according to sensor type\n",
    "- Manipulate the AT layer to filter data according to data age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acbaaee",
   "metadata": {},
   "source": [
    "## CLMS HRSI GFSC Product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5291b0-e7c6-487b-9e9b-b5e2c7c8777b",
   "metadata": {},
   "source": [
    "\n",
    "The daily cumulative Gap-filled Fractional Snow Cover (GFSC) product is generated in near real-time (NRT) for the entire EEA38+UK domain.  It is based on SAR data from the Sentinel-1 (S1) constellation and  \n",
    "optical data from the Sentinel-2 (S2) constellation. This product merges the latest observations to provide a spatially complete overview of snow conditions.\n",
    "\n",
    "The GFSC product offers the extent of snow cover per pixel as a percentage (0% – 100%) with a spatial resolution of 60m x 60m. It utilizes Fractional Snow Cover (FSC), Wet/Dry Snow (WDS), and SAR Wet Snow  \n",
    "(SWS) products as inputs to create a comprehensive composite of snow conditions, reducing observational gaps caused by clouds and limited sensor coverage on a daily basis. The product applies the on-ground  \n",
    "FSC and SWS data and presents the combined information as FSC.\n",
    "\n",
    "For more information about the GFSC product, please refer to the <a href=\"https://land.copernicus.eu/user-corner/technical-library/hrsi-snow-pum\">Product User Manual (PUM).</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0050ea",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Before we begin, we need to prepare our environment by installing and importing the necessary Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952102e9",
   "metadata": {},
   "source": [
    "### Install the WEkEO HDA Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ada2f8",
   "metadata": {},
   "source": [
    "The WEkEO HDA client is a Python-based library that supports both Python 2.7.x and Python 3.\n",
    "\n",
    "To install the WEkEO HDA client using the package management system pip, run the following command on Unix/Linux:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d97ecd",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install hda -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970329d9-e9f6-49cb-b646-e2a5cddec6b7",
   "metadata": {},
   "source": [
    "### Load Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d503a082",
   "metadata": {},
   "source": [
    "Please verify that the following requirements are installed before proceeding to the next step:\n",
    "   - `xmltodict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136b4bc0-1ab5-4722-a54f-b3fb039617ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, datetime, dateutil, shutil, tempfile, zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xmltodict\n",
    "\n",
    "from osgeo import gdal\n",
    "from matplotlib.colors import ListedColormap\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357066c0",
   "metadata": {},
   "source": [
    "### Load WEkEO HDA client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08afe6b9",
   "metadata": {},
   "source": [
    "## HDA Client Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b24b1",
   "metadata": {},
   "source": [
    "### WEkEO Account Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6cd4d0",
   "metadata": {},
   "source": [
    "If you don't have a WEkEO account, please self-register at the <a href='https://my.wekeo.eu/web/guest/user-registration' target='_blank'>WEkEO registration page</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeffedf",
   "metadata": {},
   "source": [
    "### API Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e1d57",
   "metadata": {},
   "source": [
    "To interact with WEkEO's Harmonised Data Access API, ensure the file `$HOME/.hdarc` exists with the URL to the API endpoint, and your username and password.  \n",
    "For example, to check if the `.hdarc` file exists in the $HOME directory, open a terminal and run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b42ffb4",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ls $HOME/.hdarc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f450e6e3",
   "metadata": {},
   "source": [
    "Then, copy the code below into the file `$HOME/.hdarc` (in your Unix/Linux environment) and replace the placeholders with your WEkEO account credentials:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f05ece",
   "metadata": {},
   "source": [
    "```yaml\n",
    "user_name: #############\n",
    "password: #############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9323098",
   "metadata": {},
   "source": [
    "The hda client provides a fully compliant Python 3 client that can be used to search and download products using the Harmonized Data Access WEkEO API.\n",
    "HDA is RESTful interface allowing users to search and download WEkEO datasets.\n",
    "Documentation about its usage can be found at the <a href='https://www.wekeo.eu/' target='_blank'>WEkEO website</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcecfa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hda import Client\n",
    "\n",
    "hda_client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788350d4",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbe72a0",
   "metadata": {},
   "source": [
    "## Process data with HDA Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2687abac-cda8-4fbd-9dc8-b6b3ac1c5691",
   "metadata": {},
   "source": [
    "### Search products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f9abf7-1bcf-41a8-a8e2-1146d27d3955",
   "metadata": {},
   "source": [
    "To search datasets, you need to construct a JSON query. You can create this query JSON manually or copy it from a manual search in the WEkEO Data Explorer.\n",
    "<div>\n",
    "<figure><img src='../../media/snow_and_ice/apicall.png' height='400px' />\n",
    "    <figcaption><i>S2 Tile T32VMN</i></figcaption>\n",
    "</figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7da694b-ac40-48ff-b977-4ed7e1baebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "  \"dataset_id\": \"EO:CRYO:DAT:HRSI:GFSC\",\n",
    "  \"bbox\": [\n",
    "    4.0488399662761605,\n",
    "    60.64709920038568,\n",
    "    9.213189474039462,\n",
    "    61.81526952644772\n",
    "  ],\n",
    "  \"observed_start\": \"2022-03-13T00:00:00.000Z\",\n",
    "  \"observed_end\": \"2022-03-13T00:00:00.000Z\",\n",
    "  \"cloudCover\": \"30\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf8a3e8-d68a-42fb-8ff4-a78c59e03c25",
   "metadata": {},
   "source": [
    "For our working example, we will create a query that specifies a single day and tile. In this case, we will use tile T32TVM in the Scandinavian mountains on March 13, 2022:\n",
    "\n",
    "<figure><img src='../../media/snow_and_ice/T32VMN.png' width='400px' />\n",
    "    <figcaption><i>S2 Tile T32VMN</i></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fd71676-e173-44d5-8fdf-e22afa5ca0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query by tile and date\n",
    "tile = 'T32VMN'\n",
    "day = '13.03.2022'\n",
    "\n",
    "query = {\n",
    "  \"dataset_id\": \"EO:CRYO:DAT:HRSI:GFSC\",\n",
    "  \"observed_start\": datetime.datetime.strptime(day,\"%d.%m.%Y\").strftime(\"%Y-%m-%dT00:00:00.000Z\"),\n",
    "  \"observed_end\": datetime.datetime.strptime(day,\"%d.%m.%Y\").strftime(\"%Y-%m-%dT00:00:00.000Z\"),\n",
    "  \"productIdentifier\": tile\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9ca41b-d9eb-47f5-a3ec-fc1851b68390",
   "metadata": {},
   "source": [
    "Use the HDA Client and the query to search the database, configuring a shorter timeout to handle potential connection or account issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31605175-b5de-4c8b-879e-20cbf59a9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_dir = os.path.realpath(\"../../data/download/snow-and-ice/products\")\n",
    "\n",
    "hda_client.time_sleep = 10\n",
    "hda_client.timeout = 10\n",
    "\n",
    "try:\n",
    "    matches = hda_client.search(query)\n",
    "    hda_success = True\n",
    "except Exception as e:\n",
    "    hda_success = False\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4abc5b1-3c9e-4950-9faa-6673e27991f2",
   "metadata": {},
   "source": [
    "If a problem occurs, such as the user not being registered, create an object to handle any previously downloaded products:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30cd6c49-2ac9-4247-8360-2e5496316d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDA Client response successful. HDA Client will be used.\n"
     ]
    }
   ],
   "source": [
    "if not hda_success:\n",
    "    matches = []\n",
    "    for product in os.listdir(prod_dir):\n",
    "        try:\n",
    "            # test if folder name fits the product filename format\n",
    "            day = datetime.datetime.strptime(product.split('_')[1].split('-')[0],\"%Y%m%d\")\n",
    "            curation_time = datetime.datetime.utcfromtimestamp(int(product.split('_')[5]))\n",
    "            # add product name to the object in the form that it can be used in the line later\n",
    "            # matches[0].results[0]['productInfo']['product']\n",
    "            match = lambda: None\n",
    "            match.results = [{'productInfo':{'product':product}}]\n",
    "            matches.append(match)\n",
    "        except:\n",
    "            print(\"A folder/file in products folder is not a valid product. Skipped.\")\n",
    "    print(len(matches), \"products found in products folder.\")\n",
    "else:\n",
    "    print(\"HDA Client response successful. HDA Client will be used.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501267ab-da1a-4484-83af-8ee78fef51ff",
   "metadata": {},
   "source": [
    "Parse the response from the HDA client and create a list of dictionaries with additional metadata to manage the data more efficiently.  \n",
    "The list structure is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e77aa-ccf4-471e-86f7-a1c6ebe09544",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    {\n",
    "        'title': str, \n",
    "        'tile': str, \n",
    "        'day': datetime.datetime, \n",
    "        'curation_time': datetime.datetime, \n",
    "        'dir': str\n",
    "    },\n",
    "    {\n",
    "        'title': str, \n",
    "        'tile': str, \n",
    "        'day': datetime.datetime, \n",
    "        'curation_time': datetime.datetime, \n",
    "        'dir': str\n",
    "    }\n",
    "];\n",
    "\n",
    "# only for descriptive usage. this cell does not do anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759af917-7109-47b9-a875-49ce27bef28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(matches), \"products found\")\n",
    "\n",
    "# reparse response for a custom list\n",
    "products = []\n",
    "for match in matches:        \n",
    "    product = match.results[0]['id']\n",
    "    tile = product.split('_')[3]\n",
    "    day = datetime.datetime.strptime(product.split('_')[1].split('-')[0],\"%Y%m%d\")\n",
    "    curation_time = datetime.datetime.utcfromtimestamp(int(product.split('_')[5]))\n",
    "    products.append({\n",
    "        'title':product,\n",
    "        'tile':tile,\n",
    "        'day':day,\n",
    "        'curation_time':curation_time\n",
    "    })\n",
    "    \n",
    "# summarize products \n",
    "print(\"Day\\t\\tTile\\tCuration time\")\n",
    "for product in products:\n",
    "    print(\n",
    "        '\\t'.join([\n",
    "            str(product['day']).split()[0],product['tile'],str(product['curation_time'])\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "if products == []:\n",
    "    print(\"No products are available in the disk. Rest of the notebook will not work.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ccf5ea",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a249f9-1ae1-48c6-85e5-fc6754911e95",
   "metadata": {},
   "source": [
    "Download the products to temporary folders and then move them to the \"products directory\" defined at the beginning.\n",
    "<li>Products are downloaded as zip files but without file extensions. Extract the files before moving them to the products directory.</li>\n",
    "<li>If the products have already been downloaded (i.e., the folder exists), skip the download.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186b8de-8633-48d0-b96d-0c641e421d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(prod_dir,exist_ok=True)\n",
    "for product in products:\n",
    "    if product['title'] not in os.listdir(prod_dir):\n",
    "        # use a temporary directory\n",
    "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "            # find the products in the HDA client response and call download method\n",
    "            [match.download(download_dir = tmp_dir) for match in matches if match.results[0]['id'] == product['title'] ]\n",
    "            # unzip\n",
    "            with zipfile.ZipFile(os.path.join(tmp_dir,product['title']) + '.zip') as zf:\n",
    "                zf.extractall(os.path.join(tmp_dir))\n",
    "            # copy to the \"real\" product dir\n",
    "            shutil.copytree(os.path.join(tmp_dir,product['title']),os.path.join(prod_dir,product['title']))\n",
    "            print(product['title'],\"was downloaded to\", prod_dir)\n",
    "    else:\n",
    "        print(product['title'],\"is already in product directory\")\n",
    "    # add directory information to be used later\n",
    "    product['dir'] = os.path.join(prod_dir,product['title'])\n",
    "\n",
    "# Note: HDA Client can download all results at once:\n",
    "# matches.download(download_dir = path_to_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c84cf",
   "metadata": {},
   "source": [
    "### Read and Visualize Products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26f7a3a-b127-4e80-b557-db56e50f00da",
   "metadata": {},
   "source": [
    "Create functions to read product rasters and metadata, and store them compactly in dictionaries.  \n",
    "The main function will take the directory and title of the product as arguments and return a single dictionary containing all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "006f70b9-1971-4650-a0ab-a694bce23111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read tif image\n",
    "def readTif(file_tif):\n",
    "\n",
    "    ds = gdal.Open(file_tif)\n",
    "    # Projection\n",
    "    proj = ds.GetProjection()\n",
    "    # Raster data\n",
    "    data = ds.GetRasterBand(1).ReadAsArray()\n",
    "    # colormap\n",
    "    color_table = ds.GetRasterBand(1).GetRasterColorTable()\n",
    "    cmp = None\n",
    "    if color_table is not None:\n",
    "        cmp = []\n",
    "        for i in range(color_table.GetCount()):\n",
    "            color = color_table.GetColorEntry(i)\n",
    "            cmp.append((color[0]/255, color[1]/255, color[2]/255))\n",
    "    ds = None\n",
    "    return data, proj, cmp\n",
    "\n",
    "# function to read all rasters and xml metadata of gfsc\n",
    "def readProductFiles(directory,title):   \n",
    "    # read tif rasters\n",
    "    gf, proj_gf, cmp_gf = readTif(os.path.join(directory,title) + '_GF.tif')\n",
    "    qc, proj_qc, cmp_qc = readTif(os.path.join(directory,title) + '_QC.tif')\n",
    "    qcflags = readTif(os.path.join(directory,title) + '_QCFLAGS.tif')[0]\n",
    "    at = readTif(os.path.join(directory,title) + '_AT.tif')[0]\n",
    "    \n",
    "    # read xml metadata\n",
    "    meta = xmltodict.parse(open(os.path.join(directory,title) + '_MTD.xml','r').read())\n",
    "    \n",
    "    return gf, cmp_gf, qc, cmp_qc, qcflags, at, meta, proj_gf\n",
    "\n",
    "# function to organize data into single dictonary\n",
    "def readProductData(directory,title):\n",
    "    gf, cmp_gf, qc, cmp_qc, qcflags, at, meta, proj = readProductFiles(directory,title)\n",
    "    \n",
    "    # make a dict for convenient reading\n",
    "    productData = {\n",
    "        'GF':gf, \n",
    "        'GF_cmp':cmp_gf, \n",
    "        'QC':qc, \n",
    "        'QC_cmp':cmp_qc, \n",
    "        'QCFLAGS':qcflags, \n",
    "        'AT':at, \n",
    "        'meta':meta, \n",
    "        'proj':proj\n",
    "    }\n",
    "    \n",
    "    return productData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68211610-945f-4e21-9018-559ef00ebd12",
   "metadata": {},
   "source": [
    "First, we will read the data and metadata of the first product in the list using the functions and directories defined previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1176208a-18c3-448b-995a-6f46ce25b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = products[0]\n",
    "productData = readProductData(product['dir'],product['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92ceba-f583-467a-89d8-15ddd9cc1e73",
   "metadata": {},
   "source": [
    "The color table in the product includes a \"No data\" label (255) set as transparent. Since the notebook background is white, \"No data\" pixels will be displayed as white, making them indistinguishable from snow pixels. Therefore, we should use a different color for \"No data\" pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3cdd8b4-a8ab-4719-9913-3da225d8cffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "productData['GF_cmp'][-1] = (255/255.,192/255.,203/255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45265d8-7339-4e3c-b23c-6793fe8840e9",
   "metadata": {},
   "source": [
    "The default figure size of \"matplotlib\" is too small for the screen, so we need to modify it to enhance visibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d429f6b9-8f08-4613-abf3-2c3dfacbb906",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde397be-113b-4f52-94e9-7bc323ceea1b",
   "metadata": {},
   "source": [
    "Next, we will draw the GF layer using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c946f0f-3126-4efa-93e0-ba950fccb5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(productData['GF'], cmap = ListedColormap(productData['GF_cmp']), interpolation = 'nearest');\n",
    "plt.clim(0, 255)\n",
    "plt.colorbar();\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902abe0-1b8f-41ab-8cd9-702f340e7e04",
   "metadata": {},
   "source": [
    "This layer shows gap-filled FSC data, which includes data from up to 7 days before. The XML metadata in the product contains information from all the input products, allowing us to list the input products, their sensing times, and calculate the age of the data relative to the GFSC product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d5ec5f-5851-4442-a580-f42839e96fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TYPE\\tSENSING TIME\\t\\tAGE')\n",
    "for input_meta in productData['meta']['gmd:MD_Metadata']['gmd:series']['gmd:DS_OtherAggregate']['gmd:seriesMetadata']:\n",
    "    input_title = input_meta['gmd:MD_Metadata']['gmd:fileIdentifier']['gco:CharacterString']\n",
    "    input_type = input_title.split('_')[0]\n",
    "    input_startDate = dateutil.parser.isoparse(input_meta['gmd:MD_Metadata']['gmd:identificationInfo']['gmd:MD_DataIdentification']['gmd:extent']['gmd:EX_Extent']['gmd:temporalElement']['gmd:EX_TemporalExtent']['gmd:extent']['gml:TimePeriod']['gml:beginPosition'])\n",
    "    input_startDate = input_startDate.replace(microsecond=0)\n",
    "    input_age = product['day'] + datetime.timedelta(days=1) - input_startDate\n",
    "    print(input_type + '\\t' + input_startDate.strftime('%Y-%m-%d %H:%M:%S') + '\\t' + str(input_age))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f181316-06f5-4818-8f80-68968c719caa",
   "metadata": {},
   "source": [
    "Although the XML metadata provides temporal information as a list, the AT layer contains temporal information for each pixel. The sensing time of each pixel is encoded as \"Unix time\" (seconds since January 1, 1970) in the AT layer. We can create a raster of \"age\" to show the age of the data in days (decimal) from the end of the product day (e.g., the age for a sensing at noon on the same day will be 12 hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "661a5016-d275-4c00-a0d0-3e7c8c7c35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_midnight_timestamp = datetime.datetime.timestamp(product['day'] + datetime.timedelta(days=1))\n",
    "productData['age'] = (product_midnight_timestamp - productData['AT'])/(60*60*24.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1c6627-c0fa-4ea5-9566-a42f78bcb488",
   "metadata": {},
   "source": [
    "When \"No data\" is present, the AT layer has a value of \"0\". To handle this, we can use \"NaN\" in the new age raster instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76048931-3397-482a-964a-5c7ebf4f41cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.place(productData['age'],productData['AT'] == 0,np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22504de-6f02-4649-8835-c00af2d025e6",
   "metadata": {},
   "source": [
    "Finally, we will draw the new \"age\" raster using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d375d4-9e18-4ee0-b889-1ba79b95758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(productData['age'],  cmap = 'tab20b', interpolation = 'nearest');\n",
    "plt.colorbar();\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce4e848",
   "metadata": {},
   "source": [
    "### Manipulating AT layer to filter out data according to age of the pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d37fe4-dc13-4046-b8d3-b51c9b1380bc",
   "metadata": {},
   "source": [
    "Using the age raster, we can filter out pixels that are \"too old\" for our analysis. We will create a new GF raster that includes only the pixels with an \"age\" of no more than 4 days (i.e., data that is at most 3 days old).\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "Note: An \"invalid value encountered\" warning may appear due to np.nan values in the age raster, but these pixels will be excluded from the results and won't affect the outcome.\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0b3219-4d1a-4f32-a50a-282398fa0d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_4days = deepcopy(productData['GF'])\n",
    "np.place(gf_4days, productData['age'] > 4, 255)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"GF\")\n",
    "plt.imshow(\n",
    "    productData['GF'], cmap = ListedColormap(productData['GF_cmp']), interpolation = 'nearest'\n",
    ");\n",
    "plt.clim(0, 255)\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);\n",
    "# change the color to a different one\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"4 Days Mask\")\n",
    "plt.imshow(\n",
    "    productData['age'] <= 4, cmap = 'PiYG', interpolation = 'nearest'\n",
    ");\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"GF 4 Days\")\n",
    "plt.imshow(\n",
    "    gf_4days, cmap = ListedColormap(productData['GF_cmp']), interpolation = 'nearest'\n",
    ");\n",
    "plt.clim(0, 255)\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86507ae2",
   "metadata": {},
   "source": [
    "### Manipulating QCFLAGS layer to filter out data according to sensor type of the pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5610a-a9b2-427f-87ff-9cb3d064b209",
   "metadata": {},
   "source": [
    "The QCFLAGS layer is encoded bitwise, containing information for seven different cases in a combined format. Therefore, reading integer values directly from the raster will not be meaningful.\n",
    "\n",
    "Next, we will draw the QCFLAGS raster using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc318e6-4167-48ae-a504-86f453b21b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"QCFLAGS\")\n",
    "plt.imshow(\n",
    "    productData['QCFLAGS'], cmap = 'Greys', interpolation = 'nearest'\n",
    ");\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aafcb0-6580-4440-8177-8747d41ad232",
   "metadata": {},
   "source": [
    "We need to read the raster bit by bit and interpret the information according to the guidelines in  <a href=\"https://land.copernicus.eu/user-corner/technical-library/hrsi-snow-pum\">the product user manual:</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d469c0c-7342-409b-9972-b22e8965b869",
   "metadata": {},
   "source": [
    "➔ bit 0: sun elevation angle too\n",
    "low for an accurate\n",
    "topographic correction (from\n",
    "MAJA) (active=1) (only valid if\n",
    "bit 6 is 0)\n",
    "\n",
    "➔ bit 1: solar elevation angle\n",
    "tangent to slope (from MAJA)\n",
    "(active=1) (only valid if bit 6\n",
    "is 0)\n",
    "\n",
    "➔ bit 2: water (from EU-Hydro)\n",
    "(active=1)\n",
    "\n",
    "➔ bit 3: TCD too high for\n",
    "accurate forest correction\n",
    "(TCD>90%) (active=1) (only\n",
    "valid if bit 6 is 0)\n",
    "\n",
    "➔ bit 4: snow detected under\n",
    "thin clouds (active=1) (only\n",
    "valid if bit 6 is 0)\n",
    "\n",
    "➔ bit 5: TCD not defined or not\n",
    "available (active=1) (only\n",
    "valid if bit 6 is 0)\n",
    "\n",
    "➔ bit 6: sensor type of the\n",
    "satellite data (optical=0,\n",
    "radar=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f482e-c81a-484b-8f27-4891f65cfc82",
   "metadata": {},
   "source": [
    "Create a function that uses bit operations to read a single bit as a boolean raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe90ac28-25de-4d24-afba-5a26821aac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBit(data,bit):\n",
    "    # shift the bits to the right until the bit in question is in first digit\n",
    "    mask = np.right_shift(data,bit)\n",
    "    # apply \"AND 00000001\" operation to get the value as 0 or 1.\n",
    "    mask = np.bitwise_and(mask,1)\n",
    "    return mask.astype(bool)\n",
    "\n",
    "# Google \"nth bit of a number\" for the theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cef9962-b6c7-42e0-ac05-101b988689d5",
   "metadata": {},
   "source": [
    "Read all the bits and visualize them using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfbcb7f-d115-4771-a194-b020d904cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bit in range(1,7):\n",
    "    plt.subplot(2, 3, bit)\n",
    "    plt.title(\"Bit \" + str(bit))\n",
    "    plt.imshow(\n",
    "        getBit(productData['QCFLAGS'],bit), cmap = 'binary', interpolation = 'nearest'\n",
    "    );\n",
    "    plt.xticks([]);\n",
    "    plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6760ee33-ef62-49c0-bf6c-fe88c7564df5",
   "metadata": {},
   "source": [
    "Another example of how to read the QCFLAGS raster can be found in \"Webinar #2 (13 Oct. 2022): High Resolution Snow and Ice Monitoring\" on the <a href=\"https://land.copernicus.eu/pan-european/biophysical-parameters/high-resolution-snow-and-ice-monitoring/user-section\">CLMS HRSI User Section website.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6ae688-e879-4e3e-a818-1c0f6770175b",
   "metadata": {},
   "source": [
    "Now, we can use the same function to filter or utilize the GF layer based on different information from QCFLAGS. First, we can separate the GF raster by sensor type: if Bit 6 is 1, the pixel is from radar (S1); if Bit 6 is 0, the sensor is optical (S2). We can create rasters and replace the filtered values with the \"no data\" value (255):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f788ce1d-c62e-4d25-9331-6364c800e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_optical = deepcopy(productData['GF'])\n",
    "gf_radar = deepcopy(productData['GF'])\n",
    "np.place(gf_radar, ~getBit(productData['QCFLAGS'],6), 255)\n",
    "np.place(gf_optical, getBit(productData['QCFLAGS'],6), 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494a6c48-7119-44c9-8551-575e18c346a3",
   "metadata": {},
   "source": [
    "Visualize the separated rasters together using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f995ffb-5e6e-43e3-a215-83ec353fc0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"GF\")\n",
    "plt.imshow(\n",
    "    productData['GF'], cmap = ListedColormap(productData['GF_cmp']),interpolation = 'nearest'\n",
    ");\n",
    "plt.clim(0, 255)\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Optical only\")\n",
    "plt.imshow(\n",
    "    gf_optical, cmap = ListedColormap(productData['GF_cmp']),interpolation = 'nearest'\n",
    ");\n",
    "plt.clim(0, 255)\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Radar only\")\n",
    "plt.imshow(\n",
    "    gf_radar, cmap = ListedColormap(productData['GF_cmp']),interpolation = 'nearest'\n",
    ");\n",
    "plt.clim(0, 255)\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffc2e90",
   "metadata": {},
   "source": [
    "### One Last Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab71dc3f-3ce8-424c-9f02-e78c1a84092e",
   "metadata": {},
   "source": [
    "We can combine information from the AT and QCFLAGS layers to filter pixels from the GF layer, for example, selecting only those from the optical sensor and not older than 2 days.\n",
    "\n",
    "<table>\n",
    "<tr><td>\n",
    "Note: An \"invalid value encountered\" warning may appear due to np.nan values in the age raster, but these pixels will be excluded from the results and won't affect the outcome.\n",
    "</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0734b065-50ac-4c76-abc4-6765295dd9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_day_optical = deepcopy(productData['GF'])\n",
    "np.place(gf_day_optical, getBit(productData['QCFLAGS'],6), 255)\n",
    "np.place(gf_day_optical, productData['age'] > 1, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd47156-3abe-4db2-b927-4feffe82f978",
   "metadata": {},
   "source": [
    "Visualize both the GF layer and the filtered GF layer using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2209a-0917-4204-8334-f2e334864eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"GF\")\n",
    "plt.imshow(\n",
    "    productData['GF'], cmap = ListedColormap(productData['GF_cmp']), interpolation = 'nearest'\n",
    ");\n",
    "plt.clim(0, 255)\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"1 day  Optical Only\")\n",
    "plt.imshow(\n",
    "    gf_day_optical, cmap = ListedColormap(productData['GF_cmp']), interpolation = 'nearest'\n",
    ");\n",
    "plt.clim(0, 255)\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710559e6",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5865fcde",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4b3ec04",
   "metadata": {},
   "source": [
    "To ensure a clean workspace and remove all downloaded files and processing artifacts created during this session, run the following code. This will delete any files that were downloaded and processed within this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "paths_to_cleanup = [\n",
    "    prod_dir\n",
    "]\n",
    "\n",
    "for path in paths_to_cleanup:\n",
    "    if os.path.isfile(path):\n",
    "        os.remove(path)\n",
    "    elif os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "\n",
    "print(\"Cleanup complete. All downloaded and processed files have been removed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
